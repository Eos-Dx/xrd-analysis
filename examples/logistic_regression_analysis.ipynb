{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01338603",
   "metadata": {},
   "source": [
    "# Logistic Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import necessary packages\n",
    "\"\"\"\n",
    "import os\n",
    "import glob \n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "\"\"\"\n",
    "Imports from eosdxanalysis.preprocessing codebase\n",
    "\"\"\"\n",
    "from eosdxanalysis.preprocessing.utils import find_centroid\n",
    "from eosdxanalysis.models.feature_engineering import EngineeredFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1139e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "h=256\n",
    "w=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import data set\n",
    "\"\"\"\n",
    "# Set filepaths\n",
    "filesdir = \"/home/jfriedman/EosDx/data/2022_08_05_all_measurements_library/\"\n",
    "\n",
    "timestamp = \"20220805T195535.446437\"\n",
    "\n",
    "database_filename = \"2022_08_04_measurements_database.csv\"\n",
    "\n",
    "output_style = \"centered_rotated_quad_folded\"\n",
    "# classifications = [\"normal\", \"cancer\"]\n",
    "classification = \"measurements\"\n",
    "\n",
    "datalist = []\n",
    "filenames = []\n",
    "\n",
    "# Set directory\n",
    "data_dir = \"preprocessed_\" + classification + \"_\" + timestamp\n",
    "# print(classification.capitalize() + \" input folder: \" + data_dir)\n",
    "\n",
    "input_dir = os.path.join(filesdir, data_dir, output_style)\n",
    "\n",
    "print(input_dir)\n",
    "\n",
    "# Get files list\n",
    "input_filenames = glob.glob(os.path.join(input_dir,\"*.txt\"))\n",
    "input_filenames.sort()\n",
    "\n",
    "file_count = len(input_filenames)\n",
    "\n",
    "print(\"Number of files: \" + str(file_count))\n",
    "\n",
    "# Store data\n",
    "image_data = np.zeros((file_count, h, w),dtype=np.uint16)\n",
    "for jdx, input_file in enumerate(input_filenames):\n",
    "    image_data[jdx] = np.loadtxt(input_file,dtype=np.uint16)\n",
    "        \n",
    "datalist = image_data\n",
    "filenames = input_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd140458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect the features\n",
    "\"\"\"\n",
    "\n",
    "# data = np.concatenate((datalist[0],datalist[1]),dtype=np.uint16)\n",
    "data = datalist\n",
    "# files = filenames[0] + filenames[1]\n",
    "files = filenames\n",
    "\n",
    "X1 = np.zeros((len(data)))\n",
    "X2 = np.zeros((len(data)))\n",
    "X3 = np.zeros((len(data)))\n",
    "X4 = np.zeros((len(data)))\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "for idx, image in enumerate(data[:]):\n",
    "    feature_class = EngineeredFeatures(image, params=None)\n",
    "    \n",
    "    x1_peak_location_ratio = feature_class.feature_5a_9a_peak_location_ratio()\n",
    "    X1[idx] = x1_peak_location_ratio\n",
    "    \n",
    "    x2_intensity_ratio, rois, centers, anchors = feature_class.feature_9a_ratio()\n",
    "    X2[idx] = x2_intensity_ratio\n",
    "\n",
    "    x3_peak_location, x3_roi, x3_roi_center, x3_anchor  = feature_class.feature_5a_peak_location()\n",
    "    X3[idx] = x3_peak_location\n",
    "    \n",
    "    x4_amorphous_intensity_ratio = feature_class.feature_amorphous_scattering_intensity_ratio()\n",
    "    X4[idx] = x4_amorphous_intensity_ratio\n",
    "\n",
    "    filename = os.path.basename(files[idx])\n",
    "    \n",
    "    visualize=False\n",
    "    if visualize:\n",
    "        fig = plt.figure(dpi=100)\n",
    "        fig.set_size_inches(4*1,4*1)\n",
    "        fig.set_facecolor(\"white\")\n",
    "\n",
    "        fig.suptitle(filename)\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "        # Plot image\n",
    "        plt.imshow(image,cmap=\"gray\")\n",
    "        \n",
    "        # Plot 5A window\n",
    "#         rect = patches.Rectangle((roi_anchor[1]-1, roi_anchor[0]-1), roi_anchor[3], roi_anchor[2],\n",
    "#                                      linewidth=1, edgecolor='b', facecolor='none')\n",
    "#         ax.add_patch(rect)\n",
    "\n",
    "        # Plot 9A windows\n",
    "        for anchor in anchors:\n",
    "            # Note: xy axis is used for this part\n",
    "            rect = patches.Rectangle((anchor[1]-1, anchor[0]-1), anchor[3], anchor[2],\n",
    "                                     linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073cb433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge the data into one dataframe\n",
    "\"\"\"\n",
    "csv_filepath = os.path.join(filesdir, data_dir, database_filename)\n",
    "df1 = pd.read_csv(csv_filepath, sep=\",\")\n",
    "\n",
    "fnames = [os.path.basename(fname) for fname in filenames]\n",
    "barcodes = [re.search(\"[A-Z][0-9]+\",fname)[0] for fname in fnames]\n",
    "\n",
    "dataframe2_arr = np.array([barcodes, X1, X2, X3, X4]).T\n",
    "\n",
    "df2 = pd.DataFrame(data=dataframe2_arr,\n",
    "                   columns=[\"Barcode\",\"5a_9a_peak_location_ratio\",\"9a_intensity_ratio\",\n",
    "                            \"5a_peak_location\", \"amorphous_scatter\"])\n",
    "\n",
    "df3 = pd.merge(df1, df2)\n",
    "df = df3\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Export features to csv\n",
    "\"\"\"\n",
    "export = True\n",
    "if export:\n",
    "    df.to_csv(os.path.join(filesdir, \"updated_features.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prep data and labels\n",
    "\"\"\"\n",
    "# Data\n",
    "X = df[[\"5a_9a_peak_location_ratio\",\"9a_intensity_ratio\",\"5a_peak_location\",\n",
    "        \"amorphous_scatter\"]].astype(float).values\n",
    "\n",
    "patient_averaging = False\n",
    "\n",
    "# Patient averaging\n",
    "if patient_averaging:\n",
    "    csv_num = df[\"Patient\"].nunique()\n",
    "\n",
    "    print(\"There are \" + str(csv_num) + \" unique samples.\")\n",
    "\n",
    "    # Y = np.zeros((X.shape[0],1))\n",
    "    # Y = df['Cancer'].values.reshape((-1,1))\n",
    "    # print(Y.shape)\n",
    "\n",
    "    # Labels\n",
    "    Y = np.zeros((csv_num,1),dtype=bool)\n",
    "    X_new = np.zeros((csv_num,2))\n",
    "\n",
    "    # Loop over each sample\n",
    "    # and average X and label Y\n",
    "\n",
    "    for idx in np.arange(csv_num):\n",
    "        # Get a sample\n",
    "        sample = df.loc[df['Barcode'] == barcodes[idx]]\n",
    "        patient = sample.values[0][1]\n",
    "        # Get all specimens from the same patient\n",
    "        df_rows = df.loc[df['Patient'] == patient]\n",
    "        indices = df_rows.index\n",
    "        # Now average across all samples\n",
    "        X_new[idx,:] = np.mean(X[indices,:],axis=0)\n",
    "        # Get the labels for the samples, first one is ok'\n",
    "        Y[idx] = df_rows[\"Cancer\"][indices[0]]\n",
    "\n",
    "\n",
    "    X = X_new\n",
    "    print(\"Total data count after averaging:\")\n",
    "    print(Y.shape)\n",
    "\n",
    "    print(\"Normal data count:\")\n",
    "    print(np.sum(Y == False))\n",
    "    print(\"Cancer data count:\")\n",
    "    print(np.sum(Y == True))\n",
    "\n",
    "\n",
    "# No patient averaging\n",
    "elif not patient_averaging:\n",
    "    Y = df[\"Cancer\"]\n",
    "\n",
    "# Check that X and Y have same number of rows\n",
    "assert(np.array_equal(X.shape[0], Y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc371e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perform Logistic Regression\n",
    "\"\"\"\n",
    "# x-axis: feature 1\n",
    "# y-axis: feature 2\n",
    "# normal: o's\n",
    "# cancer: x's\n",
    "\n",
    "# Perform logistic regression\n",
    "logreg = LogisticRegression(C=1e6,class_weight=\"balanced\")\n",
    "logreg.fit(X, Y)\n",
    "print(\"Score: {:.2f}\".format(logreg.score(X,Y)))\n",
    "\n",
    "theta1, theta2, theta3, theta4 = logreg.coef_.ravel()\n",
    "theta0 = logreg.intercept_[0]\n",
    "theta = np.array([[theta0, theta1, theta2, theta3, theta4]])\n",
    "print(\"Theta array:\")\n",
    "print(theta)\n",
    "\n",
    "\n",
    "# Plot\n",
    "# fig2 = plt.figure(1,dpi=100,figsize=(8, 8))\n",
    "# fig2.set_facecolor(\"white\")\n",
    "\n",
    "# timeformatstr = \"%Y%m%dT%H%M%S.%f\"\n",
    "# timestamp = datetime.utcnow().strftime(timeformatstr)\n",
    "# fig2.suptitle(\"Logistic Regression Analysis - \" + timestamp)\n",
    "\n",
    "# Plot linear decision boundary\n",
    "# plt.plot(x1_test, x2_test)\n",
    "\n",
    "\n",
    "# Predict\n",
    "Y_predict = theta1*X[:,0] + theta2*X[:,1] + theta3*X[:,2] + theta4*X[:,3] + theta0 > 0\n",
    "\n",
    "# Get scores\n",
    "precision = precision_score(Y, Y_predict)\n",
    "print(\"Precision:\")\n",
    "print(\"{:2.2}\".format(precision))\n",
    "recall = recall_score(Y, Y_predict)\n",
    "print(\"Recall (Sensitivity):\")\n",
    "print(\"{:2.2}\".format(recall))\n",
    "# False positive rate: false positives\n",
    "# Of samples identified as positive, what percentage are false\n",
    "print(\"False positive rate:\")\n",
    "false_positives = np.sum(Y[Y_predict == True] == False)\n",
    "predicted_positives = np.sum(Y_predict == True)\n",
    "false_positive_rate = false_positives/predicted_positives\n",
    "print(\"{:2.2}\".format(false_positive_rate))\n",
    "\n",
    "# Accuracy = number of correct predictions / total predictions\n",
    "# Balanced accuracy score, weights by counts\n",
    "balanced_accuracy = balanced_accuracy_score(Y, Y_predict)\n",
    "print(\"Balanced accuracy:\")\n",
    "print(\"{:2.2}\".format(balanced_accuracy))\n",
    "# Unbalanced accuracy\n",
    "unbalanced_accuracy = accuracy_score(Y, Y_predict)\n",
    "print(\"Unbalanced accuracy:\")\n",
    "print(\"{:2.2}\".format(unbalanced_accuracy))\n",
    "\n",
    "\n",
    "if False:\n",
    "    # Plot data\n",
    "    normal_indices = np.where(Y == False)\n",
    "    cancer_indices = np.where(Y == True)\n",
    "\n",
    "    # Normal\n",
    "    plt.scatter(X[normal_indices,0],X[normal_indices,1],color='b',marker='o',label=\"Normal\")\n",
    "    # Cancer\n",
    "    plt.scatter(X[cancer_indices,0],X[cancer_indices,1],color='r',marker='x',label=\"Cancer\")\n",
    "\n",
    "\n",
    "    # plt.xlabel(\"5A Peak Location\")\n",
    "    plt.xlabel(\"5.1A / 9.8A Peak Location Ratio\")\n",
    "    plt.ylabel(\"9.8A Intensity Ratio\")\n",
    "\n",
    "    # Set plot limits\n",
    "    x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "    y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "\n",
    "    # plt.xlim([x_min-0.01, x_max+0.01])\n",
    "    # plt.ylim([y_min-0.01,y_max+0.01])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
