{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01338603",
   "metadata": {},
   "source": [
    "# Logistic Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c912bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Install necessary packages\n",
    "\"\"\"\n",
    "\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install sklearn\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import necessary packages\n",
    "\"\"\"\n",
    "import os\n",
    "import glob \n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\"\"\"\n",
    "Imports from preprocessing codebase\n",
    "\"\"\"\n",
    "from preprocessing.center_finding import find_centroid\n",
    "from models.feature_engineering import feature_9a_ratio\n",
    "from models.feature_engineering import feature_5a_peak_location\n",
    "from models.feature_engineering import feature_5a_9a_peak_location_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1139e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Parameters\n",
    "\"\"\"\n",
    "h=256\n",
    "w=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import data set\n",
    "\"\"\"\n",
    "# Set filepaths\n",
    "filesdir = \"\"\n",
    "\n",
    "timestamp = \"\"\n",
    "\n",
    "output_style = \"quad_folded\"\n",
    "# classifications = [\"normal\", \"cancer\"]\n",
    "classification = \"samples\"\n",
    "\n",
    "datalist = []\n",
    "filenames = []\n",
    "\n",
    "# Set directory\n",
    "data_dir = \"preprocessed_\" + classification + \"_\" + timestamp\n",
    "# print(classification.capitalize() + \" input folder: \" + data_dir)\n",
    "\n",
    "input_dir = os.path.join(filesdir, data_dir, output_style)\n",
    "\n",
    "print(input_dir)\n",
    "\n",
    "# Get files list\n",
    "input_filenames = glob.glob(os.path.join(input_dir,\"*.txt\"))\n",
    "input_filenames.sort()\n",
    "\n",
    "file_count = len(input_filenames)\n",
    "\n",
    "print(\"Number of files: \" + str(file_count))\n",
    "\n",
    "# Store data\n",
    "image_data = np.zeros((file_count, h, w),dtype=np.uint16)\n",
    "for jdx, input_file in enumerate(input_filenames):\n",
    "    image_data[jdx] = np.loadtxt(input_file,dtype=np.uint16)\n",
    "        \n",
    "datalist = image_data\n",
    "filenames = input_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd140458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect the features\n",
    "\"\"\"\n",
    "\n",
    "# data = np.concatenate((datalist[0],datalist[1]),dtype=np.uint16)\n",
    "data = datalist\n",
    "# files = filenames[0] + filenames[1]\n",
    "files = filenames\n",
    "\n",
    "X1 = np.zeros((len(data)))\n",
    "X2 = np.zeros((len(data)))\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "for idx, image in enumerate(data[:]):\n",
    "#     x1_peak_location, roi, roi_center, roi_anchor =  feature_5a_peak_location(image)\n",
    "#     X1[idx] = x1_peak_location\n",
    "    x1_peak_location_ratio = feature_5a_9a_peak_location_ratio(image)\n",
    "    X1[idx] = x1_peak_location_ratio\n",
    "    \n",
    "    x2_intensity_ratio, rois, centers, anchors = feature_9a_ratio(image)\n",
    "    X2[idx] = x2_intensity_ratio\n",
    "\n",
    "\n",
    "    filename = os.path.basename(files[idx])\n",
    "    \n",
    "    visualize=False\n",
    "    if visualize:\n",
    "        fig = plt.figure(dpi=100)\n",
    "        fig.set_size_inches(4*1,4*1)\n",
    "        fig.set_facecolor(\"white\")\n",
    "\n",
    "        fig.suptitle(filename)\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "        # Plot image\n",
    "        plt.imshow(image,cmap=\"gray\")\n",
    "        \n",
    "        # Plot 5A window\n",
    "        rect = patches.Rectangle((roi_anchor[1]-1, roi_anchor[0]-1), roi_anchor[3], roi_anchor[2],\n",
    "                                     linewidth=1, edgecolor='b', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Plot 9A windows\n",
    "        for anchor in anchors:\n",
    "            # Note: xy axis is used for this part\n",
    "            rect = patches.Rectangle((anchor[1]-1, anchor[0]-1), anchor[3], anchor[2],\n",
    "                                     linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073cb433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge the data into one dataframe\n",
    "\"\"\"\n",
    "csv_file = os.path.join(filesdir, \"samples.csv\")\n",
    "df1 = pd.read_csv(csv_file, sep=\",\")\n",
    "\n",
    "fnames = [os.path.basename(fname) for fname in filenames]\n",
    "barcodes = [re.search(\"A[0-9]+\",fname)[0] for fname in fnames]\n",
    "\n",
    "dataframe2_arr = np.array([barcodes, X1, X2]).T\n",
    "\n",
    "df2 = pd.DataFrame(data=dataframe2_arr,\n",
    "                   columns=[\"Barcode\",\"5a_9a_peak_location_ratio\",\"9a_intensity_ratio\"])\n",
    "\n",
    "df3 = pd.merge(df1, df2)\n",
    "df = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Export features to csv\n",
    "\"\"\"\n",
    "export = True\n",
    "if export:\n",
    "    df.to_csv(os.path.join(filesdir, \"updated_features.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee8f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prep data and labels\n",
    "\"\"\"\n",
    "# Data\n",
    "X = np.array([X1.T, X2.T]).T\n",
    "print(X.shape)\n",
    "\n",
    "\"\"\"\n",
    "Average over samples\n",
    "\"\"\"\n",
    "csv_num = df[\"Patient\"].nunique()\n",
    "\n",
    "print(\"There are \" + str(csv_num) + \" unique samples.\")\n",
    "\n",
    "# Y = np.zeros((X.shape[0],1))\n",
    "# Y = df['Cancer'].values.reshape((-1,1))\n",
    "# print(Y.shape)\n",
    "\n",
    "# Labels\n",
    "Y = np.zeros((csv_num,1),dtype=bool)\n",
    "X_new = np.zeros((csv_num,2))\n",
    "\n",
    "# Loop over each sample\n",
    "# and average X and label Y\n",
    "\n",
    "for idx in np.arange(csv_num):\n",
    "    # Get a sample\n",
    "    sample = df.loc[df['Barcode'] == barcodes[idx]]\n",
    "    patient = sample.values[0][1]\n",
    "    # Get all specimens from the same patient\n",
    "    df_rows = df.loc[df['Patient'] == patient]\n",
    "    indices = df_rows.index\n",
    "    # Now average across all samples\n",
    "    X_new[idx,:] = np.mean(X[indices,:],axis=0)\n",
    "    # Get the labels for the samples, first one is ok'\n",
    "    Y[idx] = df_rows[\"Cancer\"][indices[0]]\n",
    "\n",
    "\n",
    "X = X_new\n",
    "print(\"Total data count after averaging:\")\n",
    "print(Y.shape)\n",
    "\n",
    "print(\"Normal data count:\")\n",
    "print(np.sum(Y == False))\n",
    "print(\"Cancer data count:\")\n",
    "print(np.sum(Y == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc371e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Perform Logistic Regression\n",
    "\"\"\"\n",
    "# x-axis: feature 1\n",
    "# y-axis: feature 2\n",
    "# normal: o's\n",
    "# cancer: x's\n",
    "\n",
    "# Perform logistic regression\n",
    "logreg = LogisticRegression(C=1e6,class_weight=\"balanced\")\n",
    "logreg.fit(X, Y)\n",
    "print(\"Score: {:.2f}\".format(logreg.score(X,Y)))\n",
    "\n",
    "theta1, theta2 = logreg.coef_.ravel()\n",
    "theta0 = logreg.intercept_[0]\n",
    "theta = np.array([[theta0, theta1, theta2]])\n",
    "print(\"Theta array:\")\n",
    "print(theta)\n",
    "\n",
    "x1_test = np.linspace(np.min(X[:,0]),np.max(X[:,0]),10)\n",
    "x2_test = -(theta1*x1_test+theta0)/theta2\n",
    "\n",
    "# Plot\n",
    "fig2 = plt.figure(1,dpi=100,figsize=(8, 8))\n",
    "fig2.set_facecolor(\"white\")\n",
    "\n",
    "fig2.suptitle(\"Logistic Regression Analysis - April 21, May 4, 9, 2022\")\n",
    "\n",
    "# Plot linear decision boundary\n",
    "plt.plot(x1_test, x2_test)\n",
    "\n",
    "\n",
    "# Predict\n",
    "Y_predict = theta1*X[:,0] + theta2*X[:,1] + theta0 > 0\n",
    "\n",
    "# Get scores\n",
    "precision = precision_score(Y, Y_predict)\n",
    "print(\"Precision:\")\n",
    "print(precision)\n",
    "recall = recall_score(Y, Y_predict)\n",
    "print(\"Recall:\")\n",
    "print(recall)\n",
    "# False positive rate: false positives\n",
    "# Of samples identified as positive, what percentage are false\n",
    "print(\"False positive rate:\")\n",
    "false_positives = np.sum(Y[Y_predict == True] == False)\n",
    "predicted_positives = np.sum(Y_predict == True)\n",
    "false_positive_rate = false_positives/predicted_positives\n",
    "print(false_positive_rate)\n",
    "\n",
    "# Accuracy = number of correct predictions / total predictions\n",
    "# Balanced accuracy score, weights by counts\n",
    "balanced_accuracy = balanced_accuracy_score(Y, Y_predict)\n",
    "print(\"Balanced accuracy:\")\n",
    "print(balanced_accuracy)\n",
    "# Unbalanced accuracy\n",
    "unbalanced_accuracy = accuracy_score(Y, Y_predict)\n",
    "print(\"Unbalanced accuracy:\")\n",
    "print(unbalanced_accuracy)\n",
    "\n",
    "\n",
    "# Plot data\n",
    "normal_indices = np.where(Y == False)\n",
    "cancer_indices = np.where(Y == True)\n",
    "\n",
    "# Normal\n",
    "plt.scatter(X[normal_indices,0],X[normal_indices,1],color='b',marker='o',label=\"Normal\")\n",
    "# Cancer\n",
    "plt.scatter(X[cancer_indices,0],X[cancer_indices,1],color='r',marker='x',label=\"Cancer\")\n",
    "\n",
    "\n",
    "# plt.xlabel(\"5A Peak Location\")\n",
    "plt.xlabel(\"5.1A / 9.8A Peak Location Ratio\")\n",
    "plt.ylabel(\"9.8A Intensity Ratio\")\n",
    "\n",
    "# Set plot limits\n",
    "x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "\n",
    "# plt.xlim([x_min-0.01, x_max+0.01])\n",
    "# plt.ylim([y_min-0.01,y_max+0.01])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
